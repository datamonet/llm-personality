{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import functions as f\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconditional prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-3.5-turbo\", \"details\": {\"E\": 38, \"I\": 25, \"S\": 19, \"N\": 62, \"T\": 35, \"F\": 34, \"J\": 51, \"P\": 15}, \"res\": \"ENTJ\", \"prompt_tokens\": 12678, \"input_tokens\": 294, \"cost\": 0.006486000000000004}\n"
     ]
    }
   ],
   "source": [
    "# gpt3.5 mbti BASELINE\n",
    "low_tem_gpt3 = f.get_mbti(model='gpt-3.5-turbo')\n",
    "\n",
    "middle_tem_gpt3 = f.get_mbti(\n",
    "    model='gpt-3.5-turbo',\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "high_tem_gpt3 = f.get_mbti(\n",
    "    model='gpt-3.5-turbo',\n",
    "    temperature=1.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditional_mbti_gpt3 = {}\n",
    "unconditional_mbti_gpt3[\"0.5 temperature unconditional\"] = low_tem_gpt3\n",
    "unconditional_mbti_gpt3[\"1 temperature unconditional\"] = middle_tem_gpt3\n",
    "unconditional_mbti_gpt3[\"1.7 temperature unconditional\"] = high_tem_gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-4o\", \"details\": {\"E\": 22, \"I\": 41, \"S\": 21, \"N\": 60, \"T\": 35, \"F\": 34, \"J\": 60, \"P\": 6}, \"res\": \"INTJ\", \"prompt_tokens\": 12351, \"input_tokens\": 279, \"cost\": 0.06314999999999993}\n"
     ]
    }
   ],
   "source": [
    "# gpt4o mbti BASELINE \n",
    "low_tem_gpt4o = f.get_mbti(model='gpt-4o')\n",
    "\n",
    "middle_tem_gpt4o = f.get_mbti(\n",
    "    model='gpt-4o',\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "high_tem_gpt4o = f.get_mbti(\n",
    "    model='gpt-4o',\n",
    "    temperature=1.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditional_mbti_gpt4o = {}\n",
    "unconditional_mbti_gpt4o[\"0.5 temperature unconditional\"] = low_tem_gpt4o\n",
    "unconditional_mbti_gpt4o[\"1 temperature unconditional\"] = middle_tem_gpt4o\n",
    "unconditional_mbti_gpt4o[\"1.7 temperature unconditional\"] = high_tem_gpt4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt4o-mini mbti BASELINE\n",
    "low_tem_gpt4omini = f.get_mbti(model='gpt-4o-mini')\n",
    "\n",
    "middle_tem_gpt4omini = f.get_mbti(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "high_tem_gpt4omini = f.get_mbti(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=1.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditional_mbti_gpt4omini = {}\n",
    "unconditional_mbti_gpt4omini[\"0.5 temperature unconditional\"] = low_tem_gpt4omini\n",
    "unconditional_mbti_gpt4omini[\"1 temperature unconditional\"] = middle_tem_gpt4omini\n",
    "unconditional_mbti_gpt4omini[\"1.7 temperature unconditional\"] = high_tem_gpt4omini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result of two models using a dict\n",
    "SAVE_PATH = 'mbti_results/llms_mbti93.json'\n",
    "\n",
    "llms_mbti = {}\n",
    "llms_mbti[\"gpt-3.5\"] = unconditional_mbti_gpt3\n",
    "llms_mbti[\"gpt-4o\"] = unconditional_mbti_gpt4o\n",
    "llms_mbti[\"gpt-4o-mini\"] = unconditional_mbti_gpt4omini\n",
    "\n",
    "# Save the dictionary as a JSON object to the file\n",
    "with open(SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(llms_mbti, json_file, indent=4)  # indent=4 for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consistency test, 3 round for each model\n",
    "# dict structure: round_i -> model_name -> temperature -> model/details\n",
    "consistency_test = {}\n",
    "\n",
    "for i in range(3):\n",
    "    consistency_test[f'round_{i}'] = {}\n",
    "    \n",
    "    for model in ['gpt-3.5-turbo', 'gpt-4o', 'gpt-4o-mini']:\n",
    "        \n",
    "        middle_tem = f.get_mbti(\n",
    "            model=model,\n",
    "            temperature=1, \n",
    "            n=1\n",
    "        )\n",
    "        high_tem = f.get_mbti(\n",
    "            model=model,\n",
    "            temperature=1.7, \n",
    "            n=1\n",
    "        )\n",
    "        \n",
    "        consistency_test[f'round_{i}'][model] = {}\n",
    "        consistency_test[f'round_{i}'][model][\"tem 1.0\"] = middle_tem\n",
    "        consistency_test[f'round_{i}'][model][\"tem 1.7\"] = high_tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbti_results/consistency_test.json\", 'w', encoding='utf8') as json_file:\n",
    "    json.dump(consistency_test, json_file, indent=4)  # indent=4 for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get consistency data for each model \n",
    "# dict structure: model_name -> middle/high_tem -> data -> each_dimension\n",
    "\n",
    "model_consistency = {}\n",
    "for model in ['gpt-3.5-turbo', 'gpt-4o', 'gpt-4o-mini']: # calculate accuracy for each model\n",
    "    acc_high_tem = {}\n",
    "    acc_middle_tem = {}\n",
    "    model_consistency[model] = {} \n",
    "    model_consistency[model][\"middle_tem\"] = {}\n",
    "    model_consistency[model][\"high_tem\"] = {}\n",
    "\n",
    "\n",
    "    \n",
    "    for i in range(3): # gather results of three round\n",
    "        details_middel = consistency_test[f'round_{i}'][model][\"tem 1.0\"][\"details\"]\n",
    "        for key in details_middel.keys():\n",
    "            if i == 0: \n",
    "                acc_middle_tem[key] = [details_middel[key]]\n",
    "            else: \n",
    "                acc_middle_tem[key].append(details_middel[key])\n",
    "                \n",
    "        details_high = consistency_test[f'round_{i}'][model][\"tem 1.7\"][\"details\"]\n",
    "        for key in details_high.keys():\n",
    "            if i == 0: \n",
    "                acc_high_tem[key] = [details_high[key]]\n",
    "            else: \n",
    "                acc_high_tem[key].append(details_high[key])\n",
    "    \n",
    "    model_consistency[model][\"middle_tem\"][\"data\"] = acc_middle_tem\n",
    "    model_consistency[model][\"high_tem\"][\"data\"] = acc_high_tem       \n",
    "    \n",
    "# calculate standered deviation\n",
    "for model in model_consistency.keys():\n",
    "    for tem in [\"middle_tem\", \"high_tem\"]:\n",
    "        model_tem = model_consistency[model][tem]\n",
    "        model_tem[\"standered deviation\"] = {}\n",
    "                \n",
    "        for dim in model_tem[\"data\"].keys():\n",
    "            model_tem[\"standered deviation\"][dim] = np.std(model_tem[\"data\"][dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbti_results/consistency_model.json\", 'w', encoding='utf8') as json_file:\n",
    "    json.dump(model_consistency, json_file, indent=4)  # indent=4 for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo': {'middle_tem': {'data': {'E': [14, 18, 14],\n",
       "    'I': [7, 3, 7],\n",
       "    'S': [9, 9, 10],\n",
       "    'N': [18, 18, 17],\n",
       "    'T': [13, 16, 16],\n",
       "    'F': [10, 7, 7],\n",
       "    'J': [19, 19, 19],\n",
       "    'P': [3, 3, 3]},\n",
       "   'standered deviation': {'E': 1.8856180831641267,\n",
       "    'I': 1.8856180831641267,\n",
       "    'S': 0.4714045207910317,\n",
       "    'N': 0.4714045207910317,\n",
       "    'T': 1.4142135623730951,\n",
       "    'F': 1.4142135623730951,\n",
       "    'J': 0.0,\n",
       "    'P': 0.0}},\n",
       "  'high_tem': {'data': {'E': [14, 13, 15],\n",
       "    'I': [7, 8, 6],\n",
       "    'S': [8, 11, 7],\n",
       "    'N': [19, 16, 20],\n",
       "    'T': [17, 10, 17],\n",
       "    'F': [6, 13, 6],\n",
       "    'J': [15, 18, 20],\n",
       "    'P': [7, 4, 2]},\n",
       "   'standered deviation': {'E': 0.816496580927726,\n",
       "    'I': 0.816496580927726,\n",
       "    'S': 1.699673171197595,\n",
       "    'N': 1.699673171197595,\n",
       "    'T': 3.2998316455372216,\n",
       "    'F': 3.2998316455372216,\n",
       "    'J': 2.0548046676563256,\n",
       "    'P': 2.0548046676563256}}},\n",
       " 'gpt-4o': {'middle_tem': {'data': {'E': [8, 8, 7],\n",
       "    'I': [13, 13, 14],\n",
       "    'S': [8, 7, 6],\n",
       "    'N': [19, 20, 21],\n",
       "    'T': [13, 10, 13],\n",
       "    'F': [10, 13, 10],\n",
       "    'J': [20, 20, 18],\n",
       "    'P': [2, 2, 4]},\n",
       "   'standered deviation': {'E': 0.4714045207910317,\n",
       "    'I': 0.4714045207910317,\n",
       "    'S': 0.816496580927726,\n",
       "    'N': 0.816496580927726,\n",
       "    'T': 1.4142135623730951,\n",
       "    'F': 1.4142135623730951,\n",
       "    'J': 0.9428090415820634,\n",
       "    'P': 0.9428090415820634}},\n",
       "  'high_tem': {'data': {'E': [8, 9, 9],\n",
       "    'I': [13, 12, 12],\n",
       "    'S': [8, 6, 8],\n",
       "    'N': [19, 21, 19],\n",
       "    'T': [12, 12, 15],\n",
       "    'F': [11, 11, 8],\n",
       "    'J': [19, 19, 19],\n",
       "    'P': [3, 3, 3]},\n",
       "   'standered deviation': {'E': 0.4714045207910317,\n",
       "    'I': 0.4714045207910317,\n",
       "    'S': 0.9428090415820634,\n",
       "    'N': 0.9428090415820634,\n",
       "    'T': 1.4142135623730951,\n",
       "    'F': 1.4142135623730951,\n",
       "    'J': 0.0,\n",
       "    'P': 0.0}}},\n",
       " 'gpt-4o-mini': {'middle_tem': {'data': {'E': [9, 9, 9],\n",
       "    'I': [12, 12, 12],\n",
       "    'S': [7, 6, 6],\n",
       "    'N': [20, 21, 21],\n",
       "    'T': [7, 6, 6],\n",
       "    'F': [16, 17, 17],\n",
       "    'J': [18, 17, 17],\n",
       "    'P': [4, 5, 5]},\n",
       "   'standered deviation': {'E': 0.0,\n",
       "    'I': 0.0,\n",
       "    'S': 0.4714045207910317,\n",
       "    'N': 0.4714045207910317,\n",
       "    'T': 0.4714045207910317,\n",
       "    'F': 0.4714045207910317,\n",
       "    'J': 0.4714045207910317,\n",
       "    'P': 0.4714045207910317}},\n",
       "  'high_tem': {'data': {'E': [8, 10, 9],\n",
       "    'I': [13, 11, 12],\n",
       "    'S': [8, 6, 7],\n",
       "    'N': [19, 21, 20],\n",
       "    'T': [7, 7, 8],\n",
       "    'F': [16, 16, 15],\n",
       "    'J': [19, 17, 20],\n",
       "    'P': [3, 5, 2]},\n",
       "   'standered deviation': {'E': 0.816496580927726,\n",
       "    'I': 0.816496580927726,\n",
       "    'S': 0.816496580927726,\n",
       "    'N': 0.816496580927726,\n",
       "    'T': 0.4714045207910317,\n",
       "    'F': 0.4714045207910317,\n",
       "    'J': 1.247219128924647,\n",
       "    'P': 1.247219128924647}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional prompt (change LLMs' mbti via prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalities = json.load(\n",
    "    open('mbti_types/personality_traits.json', 'r', encoding='utf8')\n",
    ").keys()\n",
    "\n",
    "personality_traits = json.load(\n",
    "    open('mbti_types/personality_traits.json', 'r', encoding='utf8')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt 3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "simple_35_condition_mbti = {}\n",
    "\n",
    "for p in personalities:\n",
    "\n",
    "    condi_prompt = (\n",
    "        'Your personality is'\n",
    "        + p\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    simple_35_condition_mbti[p] = result\n",
    "\n",
    "# Complex Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "complex_35_condition_mbti = {}\n",
    "\n",
    "for p in personality_traits.keys():\n",
    "\n",
    "    condi_prompt = (\n",
    "        f'You are a human with the following personality type:{p}.'\n",
    "        + f'Your traits are the following:{personality_traits[p][\"traits\"]}'\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-3.5-turbo', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    complex_35_condition_mbti[p] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt 4o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "simple_4o_condition_mbti = {}\n",
    "\n",
    "for p in personalities:\n",
    "    \n",
    "    condi_prompt = (\n",
    "        'Your personality is'\n",
    "        + p\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-4o', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    simple_4o_condition_mbti[p] = result\n",
    "    \n",
    "# Complex Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "complex_4o_condition_mbti = {}\n",
    "\n",
    "for p in personality_traits.keys():\n",
    "\n",
    "    condi_prompt = (\n",
    "        f'You are a human with the following personality type:{p}.'\n",
    "        + f'Your traits are the following:{personality_traits[p][\"traits\"]}'\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-4o', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    complex_4o_condition_mbti[p] = result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt 4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "simple_4omini_condition_mbti = {}\n",
    "\n",
    "for p in personalities:\n",
    "    \n",
    "    condi_prompt = (\n",
    "        'Your personality is'\n",
    "        + p\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-4o', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    simple_4omini_condition_mbti[p] = result\n",
    "    \n",
    "# Complex Personality-Conditioned Prompting, 1 loop for 16 personalities\n",
    "complex_4omini_condition_mbti = {}\n",
    "\n",
    "for p in personality_traits.keys():\n",
    "\n",
    "    condi_prompt = (\n",
    "        f'You are a human with the following personality type:{p}.'\n",
    "        + f'Your traits are the following:{personality_traits[p][\"traits\"]}'\n",
    "    )\n",
    "    \n",
    "    result = f.get_mbti(\n",
    "        model='gpt-4o', \n",
    "        add_sys_prompt=condi_prompt\n",
    "    )\n",
    "    \n",
    "    complex_4omini_condition_mbti[p] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "CONDI_SAVE_PATH = 'mbti_results/condition_mbti93.json'\n",
    "\n",
    "condition_mbti = {}\n",
    "condition_mbti['simple_35_condition'] = simple_35_condition_mbti\n",
    "condition_mbti['complex_35_condition'] = complex_35_condition_mbti\n",
    "condition_mbti['simple_4o_condition'] = simple_4o_condition_mbti\n",
    "condition_mbti['complex_4o_condition'] = complex_4o_condition_mbti\n",
    "condition_mbti['simple_4omini_condition'] = simple_4omini_condition_mbti\n",
    "condition_mbti['complex_4omini_condition'] = complex_4omini_condition_mbti\n",
    "\n",
    "with open(CONDI_SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(condition_mbti, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracy\n",
    "condition_results = json.load(\n",
    "    open('mbti_results/condition_mbti93.json', 'r', encoding='utf8')\n",
    ")\n",
    "\n",
    "accuracy_rate = {}\n",
    "\n",
    "for r in condition_results.keys(): # r: one of the four conditional mbti results\n",
    "    temp_acc_num = 0\n",
    "    temp_dim = [0, 0, 0, 0]\n",
    "    dim = ['I/E', 'N/S', 'F/T', 'P/J']\n",
    "    \n",
    "    for mbti_type in condition_results[r].keys(): # mbti_type: one of 16 MBTI personalities\n",
    "        res_mbti = condition_results[r][mbti_type]['res'] \n",
    "        \n",
    "        if mbti_type == res_mbti: # total accuracy\n",
    "            temp_acc_num += 1 \n",
    "        \n",
    "        for n in range(4):\n",
    "            if mbti_type[n] == res_mbti[n]: # accuracy of certain dimesion\n",
    "                temp_dim[n] += 1  \n",
    "\n",
    "    accuracy_rate[r] = {} # aggregate dict\n",
    "    accuracy_rate[r]['total'] = temp_acc_num / 16\n",
    "    \n",
    "    for d in range(4):\n",
    "        accuracy_rate[r][dim[d]] = temp_dim[d] / 16\n",
    "        \n",
    "    # print(r + ' done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_SAVE_PATH = 'mbti_results/condition_accuracy.json'\n",
    "\n",
    "with open(ACC_SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(accuracy_rate, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
