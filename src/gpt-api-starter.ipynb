{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one model, one question, certain temperature\n",
    "def get_model_answer(model, temperature, question):\n",
    "    system_prompt = 'You can only anwser one letter, A or B'\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        response_format={ \"type\": \"text\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    cost_info['prompt_tokens'] += response.usage.prompt_tokens\n",
    "    cost_info['input_tokens'] += response.usage.completion_tokens\n",
    "    \n",
    "    if model == 'gpt-3.5-turbo':\n",
    "        cost_info['cost'] += response.usage.total_tokens * 0.5/1000000\n",
    "    elif model == 'gpt-4o':\n",
    "        cost_info['cost'] += response.usage.total_tokens * 5/1000000\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbti for one model\n",
    "def get_mbti(model, temperature=0.5):\n",
    "    mbti_questions = json.load(\n",
    "        open('mbti_questions.json', 'r', encoding='utf8')\n",
    "    )\n",
    "\n",
    "    cur_model_score = {\n",
    "            'E': 0,\n",
    "            'I': 0,\n",
    "            'S': 0,\n",
    "            'N': 0,\n",
    "            'T': 0,\n",
    "            'F': 0,\n",
    "            'J': 0,\n",
    "            'P': 0\n",
    "        }\n",
    "\n",
    "    for i in range(3): \n",
    "        for q in mbti_questions.values():\n",
    "            question = q['question']\n",
    "            res = get_model_answer(\n",
    "                model=model, \n",
    "                temperature=temperature, \n",
    "                question=question+'You can only answer A or B, only one letter'\n",
    "            )\n",
    "            # print(res)\n",
    "            mbti_choice = q[res]\n",
    "            cur_model_score[mbti_choice] += 1\n",
    "        \n",
    "    e_or_i = 'E' if cur_model_score['E'] > cur_model_score['I'] else 'I'\n",
    "    s_or_n = 'S' if cur_model_score['S'] > cur_model_score['N'] else 'N'\n",
    "    t_or_f = 'T' if cur_model_score['T'] > cur_model_score['F'] else 'F'\n",
    "    j_or_p = 'J' if cur_model_score['J'] > cur_model_score['P'] else 'P'\n",
    "\n",
    "    result = {\n",
    "        'model': model,\n",
    "        'details': cur_model_score,\n",
    "        'res': ''.join([e_or_i, s_or_n, t_or_f, j_or_p])\n",
    "    }\n",
    "    \n",
    "    return(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-3.5-turbo\", \"details\": {\"E\": 44, \"I\": 19, \"S\": 23, \"N\": 58, \"T\": 36, \"F\": 33, \"J\": 52, \"P\": 14}, \"res\": \"ENTJ\", \"prompt_tokens\": 20025, \"input_tokens\": 279, \"cost\": 0.010151999999999998}\n"
     ]
    }
   ],
   "source": [
    "# gpt3.5 mbti and api cost(per round) \n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "\n",
    "result_gpt3 = get_mbti(model='gpt-3.5-turbo')\n",
    "result_gpt3 = result_gpt3 | cost_info\n",
    "print(json.dumps(result_gpt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result of two models using a dict\n",
    "SAVE_PATH = 'llms_mbti.json'\n",
    "\n",
    "llms_mbti = {}\n",
    "llms_mbti[\"gpt-3.5\"] = result_gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\": \"gpt-4o\", \"details\": {\"E\": 19, \"I\": 44, \"S\": 20, \"N\": 61, \"T\": 36, \"F\": 33, \"J\": 60, \"P\": 6}, \"res\": \"INTJ\", \"prompt_tokens\": 16695, \"input_tokens\": 279, \"cost\": 0.08486999999999997}\n"
     ]
    }
   ],
   "source": [
    "# gpt4o mbti and api cost(per round)\n",
    "cost_info = {\n",
    "    'prompt_tokens': 0,\n",
    "    'input_tokens': 0,\n",
    "    'cost': 0\n",
    "}\n",
    "\n",
    "result_gpt4o = get_mbti(model='gpt-4o')\n",
    "result_gpt4o = result_gpt4o | cost_info\n",
    "print(json.dumps(result_gpt4o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms_mbti[\"gpt-4o\"] = result_gpt4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary as a JSON object to the file\n",
    "with open(SAVE_PATH, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(llms_mbti, json_file, indent=4)  # indent=4 for pretty-printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mbti for GPT3.5 and cost per round\n",
    "- **Mbti details**\n",
    "  - model: gpt-3.5-turbo, \n",
    "  - details(3 times per questions): {E: 38, I: 25, S: 23, N: 58, T: 35, F: 34, J: 54, P: 12}, \n",
    "  - res: [ENTJ](https://www.16personalities.com/entj-personality)  \n",
    "- **Cost info per round**\n",
    "  - prompt_tokens: 20304, \n",
    "  - input_tokens: 279, \n",
    "  - cost: 0.0102915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mbti for GPT4o and cost per round\n",
    "\n",
    "- **Mbti details**\n",
    "  - model: gpt-4o, \n",
    "  - details: {E: 18, I: 45, S: 24, N: 57, T: 36, F: 33, J: 57, P: 9}, \n",
    "  - res: [INTJ](https://www.16personalities.com/intj-personality)\n",
    "- **Cost info per round**\n",
    "  - prompt_tokens: 16974, \n",
    "  - input_tokens: 279, \n",
    "  - cost: 0.08626499999999994"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
